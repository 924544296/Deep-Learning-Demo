{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch as T  \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torchvision.transforms as trans \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision.models import resnet18\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image \n",
    "import scipy as sp\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '/home/wwang/datasets/mini_imagenet/train/'\n",
    "path_val = '/home/wwang/datasets/mini_imagenet/val/'\n",
    "way = 2 # 不可改\n",
    "shot = 2\n",
    "image_size = [84, 84]\n",
    "dim_embedding = 256\n",
    "channel = 64\n",
    "margin = 1 # 0.3\n",
    "iterations = 1000000\n",
    "batch_size = 32\n",
    "path_work = \"/home/wwang/wwfewshot/work/siamesenet_3loss/\"\n",
    "device = T.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_siamesenet(Dataset):\n",
    "    #\n",
    "    def __init__(self, path):\n",
    "        # print(0)\n",
    "        category_names = os.listdir(path)\n",
    "        self.image_list = []\n",
    "        self.label_list = []\n",
    "        for label, category_name in enumerate(category_names):\n",
    "            file_names = os.listdir(path + category_name)\n",
    "            for file_name in file_names:\n",
    "                self.image_list.append(path + category_name + '/' + file_name)\n",
    "                self.label_list.append(label) \n",
    "        self.category_num = label + 1\n",
    "        self.transform = trans.Compose([trans.Resize(image_size, Image.BICUBIC),\n",
    "                                        trans.RandomHorizontalFlip(),\n",
    "                                        trans.ToTensor(),\n",
    "                                        trans.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                        ])\n",
    "    #\n",
    "    def __getitem__(self, idx):\n",
    "        label = np.zeros([way])\n",
    "        permutation = np.random.permutation(self.category_num)[:way]\n",
    "        category_random = np.random.randint(way)\n",
    "        label[category_random] = 1\n",
    "        image_support = []\n",
    "        for i, cls in enumerate(permutation):\n",
    "            ids_per_cls = np.argwhere(np.array(self.label_list) == cls).reshape([-1])\n",
    "            ids_per_cls = np.random.choice(ids_per_cls, shot+1)\n",
    "            for j in range(shot):\n",
    "                image_support.append(self.transform(Image.open(self.image_list[ids_per_cls[j]])))\n",
    "            if i == category_random:\n",
    "                image_query = self.transform(Image.open(self.image_list[ids_per_cls[shot]]))\n",
    "        image_support = T.cat(image_support)\n",
    "        return image_support, image_query, label\n",
    "    #\n",
    "    def __len__(self):\n",
    "        return iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNA(nn.Module):\n",
    "    #\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    #\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(nn.Module):\n",
    "    #\n",
    "    def __init__(self, channel, dim_embedding):\n",
    "        super().__init__()\n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.layers = nn.Sequential(\n",
    "            CNA(3, channel, 5, 1, 0),\n",
    "            CNA(channel, channel*2, 2, 2, 0),\n",
    "            CNA(channel*2, channel*2, 5, 1, 0),\n",
    "            CNA(channel*2, channel*4, 2, 2, 0),\n",
    "            CNA(channel*4, channel*4, 5, 1, 0),\n",
    "            CNA(channel*4, channel*8, 2, 2, 0),\n",
    "            nn.Conv2d(channel*8, dim_embedding, 5, 1, 0)\n",
    "        )\n",
    "    #\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    #\n",
    "    def __init__(self, channel=channel, dim_embedding=dim_embedding):\n",
    "        super().__init__()\n",
    "        self.backbone = BackBone(channel, dim_embedding)\n",
    "        # self.backbone = resnet18(pretrained=False, num_classes=dim_embedding)\n",
    "    #\n",
    "    def forward(self, image):\n",
    "        return self.backbone(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward(net, image_support, image_query):\n",
    "    n, c, h, w = image_query.shape\n",
    "    image_support = image_support.reshape([n*way*shot, c, h, w])\n",
    "    image_query = image_query.reshape([n, c, h, w])\n",
    "    #\n",
    "    net.eval()\n",
    "    embedding_support = net(image_support) # n*way*shot, dim_embedding\n",
    "    embedding_query = net(image_query).reshape([-1, dim_embedding*9]) # n*1, dim_embedding\n",
    "    #\n",
    "    embedding_support = embedding_support.reshape([n, way, shot, dim_embedding*9])\n",
    "    embedding_support_avg = T.mean(embedding_support, axis=2) # n, way, dim_embedding\n",
    "    embedding_support_avg0 = embedding_support_avg[:, 0, :] # n, dim_embedding\n",
    "    embedding_support_avg1 = embedding_support_avg[:, 1, :] # n, dim_embedding\n",
    "    distance0 = T.sqrt( T.sum( (embedding_query - embedding_support_avg0)**2, axis=1) ) # n, 1\n",
    "    distance1 = T.sqrt( T.sum( (embedding_query - embedding_support_avg1)**2, axis=1) ) # n, 1\n",
    "    return distance0, distance1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@ T.no_grad()\n",
    "def show(net, path):\n",
    "    #\n",
    "    dataloader = DataLoader(Dataset_siamesenet(path=path), batch_size=1)\n",
    "    for image_support, image_query, label in dataloader:\n",
    "        break\n",
    "    image_support = image_support.reshape([-1, way*shot, 3, image_size[0], image_size[1]])\n",
    "    #\n",
    "    plt.figure(figsize=(10, 15))\n",
    "    for i in range(way*shot+1):\n",
    "        plt.subplot(way+1, shot, i+1)\n",
    "        if i < way*shot:\n",
    "            image = image_support[0, i, :, :, :].cpu().numpy().transpose([1,2,0])\n",
    "            plt.title('Support. Label: {}'.format(int(label[0, i//shot])))\n",
    "        else:\n",
    "            image = image_query[0, :, :, :].cpu().numpy().transpose([1,2,0])\n",
    "            plt.title('Query')\n",
    "        plt.imshow(image*0.5+0.5)\n",
    "    plt.show()\n",
    "    #\n",
    "    if net is not None:\n",
    "        net.eval()\n",
    "        image_support, image_query = image_support.to(device), image_query.to(device)\n",
    "        distance0, distance1 = Forward(net, image_support, image_query)\n",
    "        print('distance0: {}, distance1: {}'.format(distance0.cpu().numpy().item(), distance1.cpu().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNet().to(device)\n",
    "show(net, path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m,h\n",
    "\n",
    "\n",
    "@ T.no_grad()\n",
    "def test(net, path, episode, batch_size=15):\n",
    "    net.eval()\n",
    "    dataloader = DataLoader(Dataset_siamesenet(path=path), batch_size=batch_size)\n",
    "    accuracies = []\n",
    "    for i, (image_support, image_query, label_relative) in enumerate(dataloader):\n",
    "        if i == episode:\n",
    "            break\n",
    "        image_support, image_query = image_support.to(device), image_query.to(device)\n",
    "        distance0, distance1 = Forward(net, image_support, image_query)\n",
    "        accuracy = np.mean( (distance0.cpu().numpy()>distance1.cpu().numpy()) == (label_relative[:,0].numpy()<label_relative[:,1].numpy()) )\n",
    "        accuracies.append(accuracy)\n",
    "    test_accuracy, h = mean_confidence_interval(accuracies)\n",
    "    return test_accuracy, h\n",
    "\n",
    "\n",
    "# net = SiameseNet().to(device)\n",
    "# test_accuracy, h = test(net, path_val, episode=600, batch_size=15)\n",
    "# print(\"val accuracy:\", test_accuracy, \"h:\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(image_support, image_query, label_relative, net, optimizer):\n",
    "    #\n",
    "    net.train()\n",
    "    distance0, distance1 = Forward(net, image_support, image_query)\n",
    "    label_relative = label_relative * 2 - 1 ######### \n",
    "    label_relative0 = label_relative[:, 0]\n",
    "    label_relative1 = label_relative[:, 1]\n",
    "    #\n",
    "    loss = T.mean( T.maximum(T.zeros(distance0.shape, device=device), distance0*label_relative0 + distance1*label_relative1 + margin) )\n",
    "    #\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(iterations, load_model):\n",
    "    #\n",
    "    iteration = np.load(path_work + 'iteration.npy', allow_pickle=True).item() if load_model else 0\n",
    "    print('Start training from iteration ', str(iteration))\n",
    "    net = PrototypicalNet().to(device)\n",
    "    optimizer = T.optim.Adam(net.parameters(), 1e-4)\n",
    "    if load_model:\n",
    "        net.load_state_dict(T.load(path_work + 'net.pt'))\n",
    "        optimizer.load_state_dict(T.load(path_work + 'optimizer.pt'))\n",
    "    #\n",
    "    dataloader = DataLoader(Dataset_siamesenet(path=path_train), batch_size=batch_size)\n",
    "    time_start = time.time()\n",
    "    for image_support, image_query, label_relative in dataloader:\n",
    "        iteration += 1\n",
    "        if iteration == iterations:\n",
    "            break\n",
    "        image_support, image_query, label_relative = image_support.to(device), image_query.to(device), label_relative.to(device)\n",
    "        loss = trainer(image_support, image_query, label_relative, net, optimizer)\n",
    "    #\n",
    "        if(iteration % 100 == 0):\n",
    "            print('Iteration: {}, loss: {}'.format(iteration, loss.detach().cpu().numpy().item()))  \n",
    "            T.save(net.state_dict(), path_work + 'net.pt')\n",
    "            T.save(net.state_dict(), path_work + 'net_backup.pt')\n",
    "            T.save(optimizer.state_dict(), path_work + 'optimizer.pt')\n",
    "            T.save(optimizer.state_dict(), path_work + 'optimizer_backup.pt')\n",
    "            np.save(path_work + 'iteration.npy', iteration) \n",
    "            show(net, path_val)\n",
    "            print('These iterations cost {} seconds'.format(time.time() - time_start))\n",
    "            time_start = time.time()\n",
    "        if(iteration % 100000 == 0):\n",
    "            test_accuracy, h = test(net, path_val, episode=600, batchsize=15)\n",
    "            print(\"val accuracy:\", test_accuracy, \"h:\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(iterations=1000, load_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train(iterations=iterations, load_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = SiameseNet().to(device)\n",
    "net.load_state_dict(T.load(path_work + 'net.pt'))\n",
    "show(net, path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.6643333333333333 h: 0.010032627879366884\n",
      "test accuracy: 0.6625555555555556 h: 0.009734515833499434\n",
      "test accuracy: 0.6686666666666666 h: 0.009563334854158856\n"
     ]
    }
   ],
   "source": [
    "total_episode = 10\n",
    "total_accuracy = 0.0\n",
    "for _ in range(total_episode):\n",
    "    test_accuracy, h = test(net, path_val, episode=600, batch_size=15)\n",
    "    print(\"test accuracy:\", test_accuracy, \"h:\", h)\n",
    "    total_accuracy += test_accuracy\n",
    "print(\"aver_accuracy:\",total_accuracy/total_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7cf6da5e8beced390049d9c6139c395b01a9f103347908593030ecc8eec04e13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
